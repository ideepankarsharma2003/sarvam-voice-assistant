{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.12.2)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os; os.chdir('..')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.12.2)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import base64\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "SARVAM_API_KEY = os.environ.get(\"SARVAM_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "print(f\"{'#'*10} successfully imported all dependencies {'#'*10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.12.2)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Recording settings\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"recorded_audio.wav\"\n",
    "\n",
    "\n",
    "# Helper Functions (same as before)\n",
    "def initialize_audio():\n",
    "    return pyaudio.PyAudio()\n",
    "\n",
    "\n",
    "def start_recording(p):\n",
    "    return p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "def stop_recording(stream, p):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "\n",
    "def save_audio(frames, p, filename=WAVE_OUTPUT_FILENAME):\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "    return filename\n",
    "\n",
    "\n",
    "def record_audio():\n",
    "    p = initialize_audio()\n",
    "    stream = start_recording(p)\n",
    "    print(\"Recording...\")\n",
    "    frames = [stream.read(CHUNK) for _ in tqdm(range(0, int(RATE / CHUNK * RECORD_SECONDS)))]\n",
    "    # print(\"Finished recording.\")\n",
    "    stop_recording(stream, p)\n",
    "    return save_audio(frames, p)\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file_path):\n",
    "    url = \"https://api.sarvam.ai/speech-to-text\"\n",
    "    headers = {\"api-subscription-key\": SARVAM_API_KEY}\n",
    "    payload = {\"language_code\": \"hi-IN\", \"model\": \"saarika:v1\"}\n",
    "\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        files = {\"file\": (audio_file_path, audio_file, \"audio/wav\")}\n",
    "        response = requests.post(url, files=files, data=payload, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"transcript\", \"\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def record_and_transcribe():\n",
    "    audio_file_path = record_audio()\n",
    "    transcription = transcribe_audio(audio_file_path)\n",
    "    if os.path.exists(audio_file_path):\n",
    "        os.remove(audio_file_path)\n",
    "    return transcription\n",
    "\n",
    "\n",
    "def play_audio(decoded_audio):\n",
    "    with wave.open(io.BytesIO(decoded_audio), 'rb') as wf:\n",
    "        p = initialize_audio()\n",
    "        stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                        channels=wf.getnchannels(),\n",
    "                        rate=wf.getframerate(),\n",
    "                        output=True)\n",
    "\n",
    "        data = wf.readframes(CHUNK)\n",
    "        while data:\n",
    "            stream.write(data)\n",
    "            data = wf.readframes(CHUNK)\n",
    "\n",
    "        stop_recording(stream, p)\n",
    "\n",
    "\n",
    "def fetch_text_to_speech_audio(text):\n",
    "    url = \"https://api.sarvam.ai/text-to-speech\"\n",
    "    headers = {\n",
    "        \"api-subscription-key\": SARVAM_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"inputs\": [text],\n",
    "        \"target_language_code\": \"hi-IN\",\n",
    "        \"speaker\": \"meera\",\n",
    "        \"pitch\": 0,\n",
    "        \"pace\": 1.65,\n",
    "        \"loudness\": 1.5,\n",
    "        \"speech_sample_rate\": 8000,\n",
    "        \"enable_preprocessing\": True,\n",
    "        \"model\": \"bulbul:v1\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"audios\", [])\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def text_to_speech(text):\n",
    "    audio_clips = fetch_text_to_speech_audio(text)\n",
    "    for audio_clip in audio_clips:\n",
    "        decoded_audio = base64.b64decode(audio_clip)\n",
    "        play_audio(decoded_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_reasoning_agent(messages:list):\n",
    "    completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages\n",
    "                )\n",
    "\n",
    "    reasoning_response =    completion.choices[0].message.strip()\n",
    "    resp= {\"role\": \"assistant\", \"content\": reasoning_response}\n",
    "    messages.append(resp)\n",
    "    return reasoning_response, messages\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
